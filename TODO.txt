1. Get stimulus set
 
   We start from VGG16 with dataset objects/animals which have a 1100*1080 dimension


2. Get firing rate responses set
3. Download pretrained models (VGG, ResNet) [OK]
4. -Reformat stimuli to fit input layer [Discuss]
    The original format is 649*405, aspect ratio : 0.624
    The format for imagenet is 224*224. I wonder if in 
    the paper by Guclu there is a discussion of this problem.
     

   -Parallelize features computation with multiprocesing
   with shared memory

5. Sparse linear model fit from feature representation
to responses 
6. Verify property of generalization
7. Decoding of latent variables
8. Retrain last layer and repeat



First compute features for all images. This is 
done in parallel for it takes 41 s for each image
ResNet on my laptop and 3 s for VGG16

Then train the sparselin to encode with
crossvalidation, estimate error on test set

Do decoding of latent variables

Retrain last layer to refine and compare decoding
performances with the first original case
